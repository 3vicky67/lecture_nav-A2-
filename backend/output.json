[
  {
    "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
    "video_file": "0Q-UQVVIUeA?si=utroSZ6ZxRQcWWUh",
    "t_start": 0.0,
    "t_end": 45.0,
    "start_time": "00:00",
    "end_time": "00:45",
    "title": "Segment 1 (00:00-00:45)",
    "snippet": "Welcome back to 30 Days of AI Challenge where hopefully by the end you'll be able to train your own AI. Anyway, let's roll in day 3, shall we? What are the day 4? Now in this gender to be eyed there is an elam's agents, foundation moral slora and for it is sure you guys know all this okay? From the fact that you've already had a lot of questions because of your agurotality you all okay? First of all what is elalance? What is agents? What is foundation moral slora right? And there is again agents. There is no two agents Fun fact this is made by AI so there will be some errors for give me. So what is elalance? Large language models right? And pretty sure you guys heard about chanceypety. So this chanceypety",
    "score": 0.12243625521659851,
    "citation": {
      "citation_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_0_0.0_45.0",
      "source": {
        "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
        "segment_idx": 0,
        "start_time": 0.0,
        "end_time": 45.0,
        "timestamp": "0.0s-45.0s"
      },
      "content": {
        "text": "Welcome back to 30 Days of AI Challenge where hopefully by the end you'll be able to train your own AI. Anyway, let's roll in day 3, shall we? What are the day 4? Now in this gender to be eyed there is an elam's agents, foundation moral slora and for it is sure you guys know all this okay? From the fact that you've already had a lot of questions because of your agurotality you all okay? First of all what is elalance? What is agents? What is foundation moral slora right? And there is again agents. There is no two agents Fun fact this is made by AI so there will be some errors for give me. So what is elalance? Large language models right? And pretty sure you guys heard about chanceypety. So this chanceypety",
        "span_start": 0,
        "span_end": 714,
        "span_text": "Welcome back to 30 Days of AI Challenge where hopefully by the end you'll be able to train your own AI. Anyway, let's roll in day 3, shall we? What are the day 4? Now in this gender to be eyed there is an elam's agents, foundation moral slora and for it is sure you guys know all this okay? From the fact that you've already had a lot of questions because of your agurotality you all okay? First of all what is elalance? What is agents? What is foundation moral slora right? And there is again agents. There is no two agents Fun fact this is made by AI so there will be some errors for give me. So what is elalance? Large language models right? And pretty sure you guys heard about chanceypety. So this chanceypety"
      },
      "metadata": {
        "relevance_score": 0.12243625521659851,
        "created_at": "2025-09-27T13:42:23.865159",
        "confidence": 0.12243625521659851
      }
    },
    "source_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_0_0.0_45.0",
    "spans": {
      "start": 0,
      "end": 714,
      "text": "Welcome back to 30 Days of AI Challenge where hopefully by the end you'll be able to train your own AI. Anyway, let's roll in day 3, shall we? What are the day 4? Now in this gender to be eyed there is an elam's agents, foundation moral slora and for it is sure you guys know all this okay? From the fact that you've already had a lot of questions because of your agurotality you all okay? First of all what is elalance? What is agents? What is foundation moral slora right? And there is again agents. There is no two agents Fun fact this is made by AI so there will be some errors for give me. So what is elalance? Large language models right? And pretty sure you guys heard about chanceypety. So this chanceypety"
    }
  },
  {
    "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
    "video_file": "0Q-UQVVIUeA?si=utroSZ6ZxRQcWWUh",
    "t_start": 30.0,
    "t_end": 75.0,
    "start_time": "00:30",
    "end_time": "01:15",
    "title": "Segment 2 (00:30-01:15)",
    "snippet": "because of your agurotality you all okay? First of all what is elalance? What is agents? What is foundation moral slora right? And there is again agents. There is no two agents Fun fact this is made by AI so there will be some errors for give me. So what is elalance? Large language models right? And pretty sure you guys heard about chanceypety. So this chanceypety and but an elama all are part of this elalance or large language models that train or like a big data set let's say the whole Instagram data of people talking and all already or internet as a whole and based on that they are being created. Now GPT is like gender to pre-transformer",
    "score": 0.08951716870069504,
    "citation": {
      "citation_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_1_30.0_75.0",
      "source": {
        "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
        "segment_idx": 1,
        "start_time": 30.0,
        "end_time": 75.0,
        "timestamp": "30.0s-75.0s"
      },
      "content": {
        "text": "because of your agurotality you all okay? First of all what is elalance? What is agents? What is foundation moral slora right? And there is again agents. There is no two agents Fun fact this is made by AI so there will be some errors for give me. So what is elalance? Large language models right? And pretty sure you guys heard about chanceypety. So this chanceypety and but an elama all are part of this elalance or large language models that train or like a big data set let's say the whole Instagram data of people talking and all already or internet as a whole and based on that they are being created. Now GPT is like gender to pre-transformer",
        "span_start": 0,
        "span_end": 648,
        "span_text": "because of your agurotality you all okay? First of all what is elalance? What is agents? What is foundation moral slora right? And there is again agents. There is no two agents Fun fact this is made by AI so there will be some errors for give me. So what is elalance? Large language models right? And pretty sure you guys heard about chanceypety. So this chanceypety and but an elama all are part of this elalance or large language models that train or like a big data set let's say the whole Instagram data of people talking and all already or internet as a whole and based on that they are being created. Now GPT is like gender to pre-transformer"
      },
      "metadata": {
        "relevance_score": 0.08951716870069504,
        "created_at": "2025-09-27T13:42:23.865257",
        "confidence": 0.08951716870069504
      }
    },
    "source_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_1_30.0_75.0",
    "spans": {
      "start": 0,
      "end": 648,
      "text": "because of your agurotality you all okay? First of all what is elalance? What is agents? What is foundation moral slora right? And there is again agents. There is no two agents Fun fact this is made by AI so there will be some errors for give me. So what is elalance? Large language models right? And pretty sure you guys heard about chanceypety. So this chanceypety and but an elama all are part of this elalance or large language models that train or like a big data set let's say the whole Instagram data of people talking and all already or internet as a whole and based on that they are being created. Now GPT is like gender to pre-transformer"
    }
  },
  {
    "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
    "video_file": "0Q-UQVVIUeA?si=utroSZ6ZxRQcWWUh",
    "t_start": 120.0,
    "t_end": 165.0,
    "start_time": "02:00",
    "end_time": "02:45",
    "title": "Segment 5 (02:00-02:45)",
    "snippet": "B codes it. Then it encodes it. So it answers how what is elal is artificial intelligence. So it starts answering that is decoding. So this gender to pre-transformer what is that? Gender to pre-transformer means generating, generating text, paste on, pre-trained information for based on the transformer architecture of neural networks. Now there is another way that elalums could learn right? Not just looking at the question then answering it based on the previous data. That is birth. But basically it looks at the question in a different way and rather than looking at the question and answer it doesn't do that. What it does is it just goes to the answer. So for example",
    "score": 0.09895818680524826,
    "citation": {
      "citation_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_4_120.0_165.0",
      "source": {
        "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
        "segment_idx": 4,
        "start_time": 120.0,
        "end_time": 165.0,
        "timestamp": "120.0s-165.0s"
      },
      "content": {
        "text": "B codes it. Then it encodes it. So it answers how what is elal is artificial intelligence. So it starts answering that is decoding. So this gender to pre-transformer what is that? Gender to pre-transformer means generating, generating text, paste on, pre-trained information for based on the transformer architecture of neural networks. Now there is another way that elalums could learn right? Not just looking at the question then answering it based on the previous data. That is birth. But basically it looks at the question in a different way and rather than looking at the question and answer it doesn't do that. What it does is it just goes to the answer. So for example",
        "span_start": 0,
        "span_end": 675,
        "span_text": "B codes it. Then it encodes it. So it answers how what is elal is artificial intelligence. So it starts answering that is decoding. So this gender to pre-transformer what is that? Gender to pre-transformer means generating, generating text, paste on, pre-trained information for based on the transformer architecture of neural networks. Now there is another way that elalums could learn right? Not just looking at the question then answering it based on the previous data. That is birth. But basically it looks at the question in a different way and rather than looking at the question and answer it doesn't do that. What it does is it just goes to the answer. So for example"
      },
      "metadata": {
        "relevance_score": 0.09895818680524826,
        "created_at": "2025-09-27T13:42:23.865271",
        "confidence": 0.09895818680524826
      }
    },
    "source_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_4_120.0_165.0",
    "spans": {
      "start": 0,
      "end": 675,
      "text": "B codes it. Then it encodes it. So it answers how what is elal is artificial intelligence. So it starts answering that is decoding. So this gender to pre-transformer what is that? Gender to pre-transformer means generating, generating text, paste on, pre-trained information for based on the transformer architecture of neural networks. Now there is another way that elalums could learn right? Not just looking at the question then answering it based on the previous data. That is birth. But basically it looks at the question in a different way and rather than looking at the question and answer it doesn't do that. What it does is it just goes to the answer. So for example"
    }
  },
  {
    "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
    "video_file": "0Q-UQVVIUeA?si=utroSZ6ZxRQcWWUh",
    "t_start": 600.0,
    "t_end": 617.0,
    "start_time": "10:00",
    "end_time": "10:17",
    "title": "Segment 21 (10:00-10:17)",
    "snippet": "Thank you.",
    "score": 0.1495829075574875,
    "citation": {
      "citation_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_20_600.0_617.0",
      "source": {
        "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
        "segment_idx": 20,
        "start_time": 600.0,
        "end_time": 617.0,
        "timestamp": "600.0s-617.0s"
      },
      "content": {
        "text": "Thank you.",
        "span_start": 0,
        "span_end": 10,
        "span_text": "Thank you."
      },
      "metadata": {
        "relevance_score": 0.1495829075574875,
        "created_at": "2025-09-27T13:42:23.865281",
        "confidence": 0.1495829075574875
      }
    },
    "source_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_20_600.0_617.0",
    "spans": {
      "start": 0,
      "end": 10,
      "text": "Thank you."
    }
  },
  {
    "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
    "video_file": "0Q-UQVVIUeA?si=utroSZ6ZxRQcWWUh",
    "t_start": 150.0,
    "t_end": 195.0,
    "start_time": "02:30",
    "end_time": "03:15",
    "title": "Segment 6 (02:30-03:15)",
    "snippet": "then answering it based on the previous data. That is birth. But basically it looks at the question in a different way and rather than looking at the question and answer it doesn't do that. What it does is it just goes to the answer. So for example everyone uses auto-character in the keyboard right? They type AI, what will come next right? Go to your keyboard and type something. I am maybe your name might come. It predicts what the next test will be. That is birth right? So it goes to both the sides and then it predicts for the next text will be. Everyone will go to end up but hope that is understandable. So alarm and all is also similar to the ongoing two end up. These are large language models and foundation models are actually similar to this two right?",
    "score": 0.0646040141582489,
    "citation": {
      "citation_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_5_150.0_195.0",
      "source": {
        "video_id": "27e7c7b8-437d-4b5c-a97f-52bfec2815c6",
        "segment_idx": 5,
        "start_time": 150.0,
        "end_time": 195.0,
        "timestamp": "150.0s-195.0s"
      },
      "content": {
        "text": "then answering it based on the previous data. That is birth. But basically it looks at the question in a different way and rather than looking at the question and answer it doesn't do that. What it does is it just goes to the answer. So for example everyone uses auto-character in the keyboard right? They type AI, what will come next right? Go to your keyboard and type something. I am maybe your name might come. It predicts what the next test will be. That is birth right? So it goes to both the sides and then it predicts for the next text will be. Everyone will go to end up but hope that is understandable. So alarm and all is also similar to the ongoing two end up. These are large language models and foundation models are actually similar to this two right?",
        "span_start": 0,
        "span_end": 766,
        "span_text": "then answering it based on the previous data. That is birth. But basically it looks at the question in a different way and rather than looking at the question and answer it doesn't do that. What it does is it just goes to the answer. So for example everyone uses auto-character in the keyboard right? They type AI, what will come next right? Go to your keyboard and type something. I am maybe your name might come. It predicts what the next test will be. That is birth right? So it goes to both the sides and then it predicts for the next text will be. Everyone will go to end up but hope that is understandable. So alarm and all is also similar to the ongoing two end up. These are large language models and foundation models are actually similar to this two right?"
      },
      "metadata": {
        "relevance_score": 0.0646040141582489,
        "created_at": "2025-09-27T13:42:23.865290",
        "confidence": 0.0646040141582489
      }
    },
    "source_id": "cite_27e7c7b8-437d-4b5c-a97f-52bfec2815c6_5_150.0_195.0",
    "spans": {
      "start": 0,
      "end": 766,
      "text": "then answering it based on the previous data. That is birth. But basically it looks at the question in a different way and rather than looking at the question and answer it doesn't do that. What it does is it just goes to the answer. So for example everyone uses auto-character in the keyboard right? They type AI, what will come next right? Go to your keyboard and type something. I am maybe your name might come. It predicts what the next test will be. That is birth right? So it goes to both the sides and then it predicts for the next text will be. Everyone will go to end up but hope that is understandable. So alarm and all is also similar to the ongoing two end up. These are large language models and foundation models are actually similar to this two right?"
    }
  }
]